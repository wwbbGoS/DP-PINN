{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../../Utilities/')\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "# from plotting import newfig, savefig\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import pylab as py\n",
    "import time\n",
    "from doe_lhs import *\n",
    "import warnings\n",
    "sys.path.insert(0, '../../../Scripts/')\n",
    "from models_pde import Net\n",
    "from pinn import *\n",
    "# from ../Scripts/helper import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_1 = 20000\n",
    "num_epochs_2 = 40000\n",
    "\n",
    "noise = 0.0\n",
    "\n",
    "## Network Architecture\n",
    "hid_dim = 128\n",
    "num_layer = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doman bounds\n",
    "lb = np.array([-1.0, 0.0])\n",
    "ub = np.array([1.0, 1.0])\n",
    "\n",
    "N0 = 512\n",
    "N_b = 100\n",
    "N_f = 5000\n",
    "# layers = [2, 100, 100, 100, 100, 2]\n",
    "\n",
    "data = scipy.io.loadmat('AC.mat')\n",
    "\n",
    "t = data['tt'].flatten()[:,None] # 201\n",
    "x = data['x'].flatten()[:,None]  # 512\n",
    "Exact = np.real(data['uu'])\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = Exact.T.flatten()[:,None]\n",
    "\n",
    "###########################\n",
    "\n",
    "st = 0.30\n",
    "tt = int(t.shape[0] * st)\n",
    "\n",
    "\n",
    "trunk1_X = X_star[ : x.shape[0] * tt]\n",
    "trunk2_X = X_star[ x.shape[0] * (tt - 1) : ]\n",
    "\n",
    "trunk1_u = u_star[ : x.shape[0] * tt]\n",
    "trunk2_u = u_star[ x.shape[0] * (tt - 1) : ]\n",
    "\n",
    "############################\n",
    "\n",
    "\n",
    "first_lb = trunk1_X.min(0) # [-5.  0.]\n",
    "first_ub = trunk1_X.max(0) # [4.9609375  0.77754418]\n",
    "\n",
    "second_lb = trunk2_X.min(0) # [-5.       0.77754418]\n",
    "second_ub = trunk2_X.max(0) # [4.9609375  1.57079633]\n",
    "\n",
    "# --------------------- first half ---------------------\n",
    "\n",
    "# initial points\n",
    "idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
    "x0_1 = x[idx_x,:]\n",
    "u0_1 = Exact[idx_x,0:1]\n",
    "\n",
    "# boundary points\n",
    "idx_t = np.random.choice(tt, N_b, replace=True)\n",
    "tb_1 = t[idx_t,:]\n",
    "\n",
    "# collocation points\n",
    "X_f_1 = first_lb + (first_ub-first_lb)*lhs(2, N_f)\n",
    "\n",
    "\n",
    "X0_1 = np.concatenate((x0_1, 0*x0_1), 1) # (x0, 0)\n",
    "Y0_1 = u0_1 \n",
    "X_lb_1 = np.concatenate((0*tb_1 + first_lb[0], tb_1), 1) # (lb[0], tb)\n",
    "X_ub_1 = np.concatenate((0*tb_1 + first_ub[0], tb_1), 1) # (ub[0], tb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/20000] [MSE loss: 0.128322] [Phy loss: 0.281994] [Total loss: 13.117682]\n",
      "[Epoch 100/20000] [MSE loss: 0.016346] [Phy loss: 0.379469] [Total loss: 2.360498]\n",
      "[Epoch 200/20000] [MSE loss: 0.001537] [Phy loss: 0.125608] [Total loss: 0.440357]\n",
      "[Epoch 300/20000] [MSE loss: 0.001301] [Phy loss: 0.097382] [Total loss: 0.322409]\n",
      "[Epoch 400/20000] [MSE loss: 0.001092] [Phy loss: 0.055821] [Total loss: 0.222114]\n",
      "[Epoch 500/20000] [MSE loss: 0.001125] [Phy loss: 0.033470] [Total loss: 0.176873]\n",
      "[Epoch 600/20000] [MSE loss: 0.001109] [Phy loss: 0.027015] [Total loss: 0.159987]\n",
      "[Epoch 700/20000] [MSE loss: 0.001109] [Phy loss: 0.029528] [Total loss: 0.160770]\n",
      "[Epoch 800/20000] [MSE loss: 0.000810] [Phy loss: 0.024655] [Total loss: 0.123711]\n",
      "[Epoch 900/20000] [MSE loss: 0.000802] [Phy loss: 0.027054] [Total loss: 0.124987]\n",
      "[Epoch 1000/20000] [MSE loss: 0.000651] [Phy loss: 0.025067] [Total loss: 0.106598]\n",
      "[Epoch 1100/20000] [MSE loss: 0.000645] [Phy loss: 0.025645] [Total loss: 0.105191]\n",
      "[Epoch 1200/20000] [MSE loss: 0.000671] [Phy loss: 0.025450] [Total loss: 0.107025]\n",
      "[Epoch 1300/20000] [MSE loss: 0.000539] [Phy loss: 0.021525] [Total loss: 0.086538]\n",
      "[Epoch 1400/20000] [MSE loss: 0.000608] [Phy loss: 0.022989] [Total loss: 0.093410]\n",
      "[Epoch 1500/20000] [MSE loss: 0.000504] [Phy loss: 0.018418] [Total loss: 0.075554]\n",
      "[Epoch 1600/20000] [MSE loss: 0.000494] [Phy loss: 0.020047] [Total loss: 0.074678]\n",
      "[Epoch 1700/20000] [MSE loss: 0.000470] [Phy loss: 0.018919] [Total loss: 0.070613]\n",
      "[Epoch 1800/20000] [MSE loss: 0.000424] [Phy loss: 0.018709] [Total loss: 0.065644]\n",
      "[Epoch 1900/20000] [MSE loss: 0.000411] [Phy loss: 0.018287] [Total loss: 0.063426]\n",
      "[Epoch 2000/20000] [MSE loss: 0.000453] [Phy loss: 0.018780] [Total loss: 0.068058]\n",
      "[Epoch 2100/20000] [MSE loss: 0.000421] [Phy loss: 0.019261] [Total loss: 0.065289]\n",
      "[Epoch 2200/20000] [MSE loss: 0.000377] [Phy loss: 0.016652] [Total loss: 0.058226]\n",
      "[Epoch 2300/20000] [MSE loss: 0.000350] [Phy loss: 0.015453] [Total loss: 0.053783]\n",
      "[Epoch 2400/20000] [MSE loss: 0.000324] [Phy loss: 0.016257] [Total loss: 0.052184]\n",
      "[Epoch 2500/20000] [MSE loss: 0.000256] [Phy loss: 0.014584] [Total loss: 0.043238]\n",
      "[Epoch 2600/20000] [MSE loss: 0.000238] [Phy loss: 0.013795] [Total loss: 0.039931]\n",
      "[Epoch 2700/20000] [MSE loss: 0.000226] [Phy loss: 0.013217] [Total loss: 0.037961]\n",
      "[Epoch 2800/20000] [MSE loss: 0.000207] [Phy loss: 0.012655] [Total loss: 0.035664]\n",
      "[Epoch 2900/20000] [MSE loss: 0.000194] [Phy loss: 0.011386] [Total loss: 0.032462]\n",
      "[Epoch 3000/20000] [MSE loss: 0.000185] [Phy loss: 0.011405] [Total loss: 0.031638]\n",
      "[Epoch 3100/20000] [MSE loss: 0.000192] [Phy loss: 0.010761] [Total loss: 0.031458]\n",
      "[Epoch 3200/20000] [MSE loss: 0.000156] [Phy loss: 0.009873] [Total loss: 0.027055]\n",
      "[Epoch 3300/20000] [MSE loss: 0.000160] [Phy loss: 0.009852] [Total loss: 0.027621]\n",
      "[Epoch 3400/20000] [MSE loss: 0.000130] [Phy loss: 0.008893] [Total loss: 0.023592]\n",
      "[Epoch 3500/20000] [MSE loss: 0.000171] [Phy loss: 0.009722] [Total loss: 0.028247]\n",
      "[Epoch 3600/20000] [MSE loss: 0.000117] [Phy loss: 0.008260] [Total loss: 0.021248]\n",
      "[Epoch 3700/20000] [MSE loss: 0.000122] [Phy loss: 0.007601] [Total loss: 0.021053]\n",
      "[Epoch 3800/20000] [MSE loss: 0.000132] [Phy loss: 0.007732] [Total loss: 0.022024]\n",
      "[Epoch 3900/20000] [MSE loss: 0.000156] [Phy loss: 0.008379] [Total loss: 0.025722]\n",
      "[Epoch 4000/20000] [MSE loss: 0.000129] [Phy loss: 0.007534] [Total loss: 0.021746]\n",
      "[Epoch 4100/20000] [MSE loss: 0.000104] [Phy loss: 0.006387] [Total loss: 0.017789]\n",
      "[Epoch 4200/20000] [MSE loss: 0.000093] [Phy loss: 0.005990] [Total loss: 0.016658]\n",
      "[Epoch 4300/20000] [MSE loss: 0.000085] [Phy loss: 0.005590] [Total loss: 0.014849]\n",
      "[Epoch 4400/20000] [MSE loss: 0.000085] [Phy loss: 0.005420] [Total loss: 0.014728]\n",
      "[Epoch 4500/20000] [MSE loss: 0.000081] [Phy loss: 0.005396] [Total loss: 0.014493]\n",
      "[Epoch 4600/20000] [MSE loss: 0.000060] [Phy loss: 0.004563] [Total loss: 0.011100]\n",
      "[Epoch 4700/20000] [MSE loss: 0.000053] [Phy loss: 0.004259] [Total loss: 0.010213]\n",
      "[Epoch 4800/20000] [MSE loss: 0.000055] [Phy loss: 0.003945] [Total loss: 0.010054]\n",
      "[Epoch 4900/20000] [MSE loss: 0.000046] [Phy loss: 0.003500] [Total loss: 0.008565]\n",
      "[Epoch 5000/20000] [MSE loss: 0.000044] [Phy loss: 0.003248] [Total loss: 0.008209]\n",
      "[Epoch 5100/20000] [MSE loss: 0.000044] [Phy loss: 0.003080] [Total loss: 0.008007]\n",
      "[Epoch 5200/20000] [MSE loss: 0.000038] [Phy loss: 0.002483] [Total loss: 0.006609]\n",
      "[Epoch 5300/20000] [MSE loss: 0.000050] [Phy loss: 0.002735] [Total loss: 0.008147]\n",
      "[Epoch 5400/20000] [MSE loss: 0.000037] [Phy loss: 0.002122] [Total loss: 0.006630]\n",
      "[Epoch 5500/20000] [MSE loss: 0.000026] [Phy loss: 0.001651] [Total loss: 0.004470]\n",
      "[Epoch 5600/20000] [MSE loss: 0.000032] [Phy loss: 0.001792] [Total loss: 0.005416]\n",
      "[Epoch 5700/20000] [MSE loss: 0.000024] [Phy loss: 0.001400] [Total loss: 0.004090]\n",
      "[Epoch 5800/20000] [MSE loss: 0.000017] [Phy loss: 0.001029] [Total loss: 0.002980]\n",
      "[Epoch 5900/20000] [MSE loss: 0.000024] [Phy loss: 0.001302] [Total loss: 0.003980]\n",
      "[Epoch 6000/20000] [MSE loss: 0.000012] [Phy loss: 0.000768] [Total loss: 0.002121]\n",
      "[Epoch 6100/20000] [MSE loss: 0.000045] [Phy loss: 0.001670] [Total loss: 0.006732]\n",
      "[Epoch 6200/20000] [MSE loss: 0.000014] [Phy loss: 0.000657] [Total loss: 0.002263]\n",
      "[Epoch 6300/20000] [MSE loss: 0.000027] [Phy loss: 0.001033] [Total loss: 0.004112]\n",
      "[Epoch 6400/20000] [MSE loss: 0.000019] [Phy loss: 0.000791] [Total loss: 0.003279]\n",
      "[Epoch 6500/20000] [MSE loss: 0.000011] [Phy loss: 0.000550] [Total loss: 0.001830]\n",
      "[Epoch 6600/20000] [MSE loss: 0.000010] [Phy loss: 0.000469] [Total loss: 0.001696]\n",
      "[Epoch 6700/20000] [MSE loss: 0.000010] [Phy loss: 0.000466] [Total loss: 0.001627]\n",
      "[Epoch 6800/20000] [MSE loss: 0.000011] [Phy loss: 0.000504] [Total loss: 0.001813]\n",
      "[Epoch 6900/20000] [MSE loss: 0.000010] [Phy loss: 0.000501] [Total loss: 0.001766]\n",
      "[Epoch 7000/20000] [MSE loss: 0.000015] [Phy loss: 0.000571] [Total loss: 0.002400]\n",
      "[Epoch 7100/20000] [MSE loss: 0.000009] [Phy loss: 0.000379] [Total loss: 0.001414]\n",
      "[Epoch 7200/20000] [MSE loss: 0.000007] [Phy loss: 0.000321] [Total loss: 0.001205]\n",
      "[Epoch 7300/20000] [MSE loss: 0.000013] [Phy loss: 0.000515] [Total loss: 0.002031]\n",
      "[Epoch 7400/20000] [MSE loss: 0.000006] [Phy loss: 0.000298] [Total loss: 0.001070]\n",
      "[Epoch 7500/20000] [MSE loss: 0.000007] [Phy loss: 0.000356] [Total loss: 0.001294]\n",
      "[Epoch 7600/20000] [MSE loss: 0.000014] [Phy loss: 0.000529] [Total loss: 0.002167]\n",
      "[Epoch 7700/20000] [MSE loss: 0.000009] [Phy loss: 0.000353] [Total loss: 0.001587]\n",
      "[Epoch 7800/20000] [MSE loss: 0.000011] [Phy loss: 0.000405] [Total loss: 0.001756]\n",
      "[Epoch 7900/20000] [MSE loss: 0.000011] [Phy loss: 0.000385] [Total loss: 0.001934]\n",
      "[Epoch 8000/20000] [MSE loss: 0.000007] [Phy loss: 0.000299] [Total loss: 0.001105]\n",
      "[Epoch 8100/20000] [MSE loss: 0.000007] [Phy loss: 0.000307] [Total loss: 0.001112]\n",
      "[Epoch 8200/20000] [MSE loss: 0.000007] [Phy loss: 0.000253] [Total loss: 0.001060]\n",
      "[Epoch 8300/20000] [MSE loss: 0.000014] [Phy loss: 0.000495] [Total loss: 0.002467]\n",
      "[Epoch 8400/20000] [MSE loss: 0.000006] [Phy loss: 0.000234] [Total loss: 0.000932]\n",
      "[Epoch 8500/20000] [MSE loss: 0.000024] [Phy loss: 0.000820] [Total loss: 0.003914]\n",
      "[Epoch 8600/20000] [MSE loss: 0.000010] [Phy loss: 0.000363] [Total loss: 0.001648]\n",
      "[Epoch 8700/20000] [MSE loss: 0.000011] [Phy loss: 0.000344] [Total loss: 0.001812]\n",
      "[Epoch 8800/20000] [MSE loss: 0.000006] [Phy loss: 0.000225] [Total loss: 0.000973]\n",
      "[Epoch 8900/20000] [MSE loss: 0.000012] [Phy loss: 0.000433] [Total loss: 0.002136]\n",
      "[Epoch 9000/20000] [MSE loss: 0.000006] [Phy loss: 0.000225] [Total loss: 0.001043]\n",
      "[Epoch 9100/20000] [MSE loss: 0.000009] [Phy loss: 0.000307] [Total loss: 0.001605]\n",
      "[Epoch 9200/20000] [MSE loss: 0.000006] [Phy loss: 0.000213] [Total loss: 0.000980]\n",
      "[Epoch 9300/20000] [MSE loss: 0.000008] [Phy loss: 0.000278] [Total loss: 0.001402]\n",
      "[Epoch 9400/20000] [MSE loss: 0.000005] [Phy loss: 0.000206] [Total loss: 0.000914]\n",
      "[Epoch 9500/20000] [MSE loss: 0.000017] [Phy loss: 0.000570] [Total loss: 0.002754]\n",
      "[Epoch 9600/20000] [MSE loss: 0.000018] [Phy loss: 0.000633] [Total loss: 0.003931]\n",
      "[Epoch 9700/20000] [MSE loss: 0.000005] [Phy loss: 0.000197] [Total loss: 0.000946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9800/20000] [MSE loss: 0.000004] [Phy loss: 0.000157] [Total loss: 0.000681]\n",
      "[Epoch 9900/20000] [MSE loss: 0.000007] [Phy loss: 0.000251] [Total loss: 0.001117]\n",
      "[Epoch 10000/20000] [MSE loss: 0.000008] [Phy loss: 0.000283] [Total loss: 0.001738]\n",
      "[Epoch 10100/20000] [MSE loss: 0.000008] [Phy loss: 0.000280] [Total loss: 0.001267]\n",
      "[Epoch 10200/20000] [MSE loss: 0.000005] [Phy loss: 0.000201] [Total loss: 0.000981]\n",
      "[Epoch 10300/20000] [MSE loss: 0.000006] [Phy loss: 0.000239] [Total loss: 0.001050]\n",
      "[Epoch 10400/20000] [MSE loss: 0.000005] [Phy loss: 0.000190] [Total loss: 0.000910]\n",
      "[Epoch 10500/20000] [MSE loss: 0.000008] [Phy loss: 0.000269] [Total loss: 0.001213]\n",
      "[Epoch 10600/20000] [MSE loss: 0.000007] [Phy loss: 0.000211] [Total loss: 0.001059]\n",
      "[Epoch 10700/20000] [MSE loss: 0.000016] [Phy loss: 0.000480] [Total loss: 0.002808]\n",
      "[Epoch 10800/20000] [MSE loss: 0.000006] [Phy loss: 0.000206] [Total loss: 0.000923]\n",
      "[Epoch 10900/20000] [MSE loss: 0.000010] [Phy loss: 0.000286] [Total loss: 0.001849]\n",
      "[Epoch 11000/20000] [MSE loss: 0.000004] [Phy loss: 0.000145] [Total loss: 0.000881]\n",
      "[Epoch 11100/20000] [MSE loss: 0.000010] [Phy loss: 0.000373] [Total loss: 0.002282]\n",
      "[Epoch 11200/20000] [MSE loss: 0.000004] [Phy loss: 0.000122] [Total loss: 0.000574]\n",
      "[Epoch 11300/20000] [MSE loss: 0.000005] [Phy loss: 0.000150] [Total loss: 0.000812]\n",
      "[Epoch 11400/20000] [MSE loss: 0.000006] [Phy loss: 0.000235] [Total loss: 0.001106]\n",
      "[Epoch 11500/20000] [MSE loss: 0.000006] [Phy loss: 0.000168] [Total loss: 0.000900]\n",
      "[Epoch 11600/20000] [MSE loss: 0.000006] [Phy loss: 0.000204] [Total loss: 0.001016]\n",
      "[Epoch 11700/20000] [MSE loss: 0.000006] [Phy loss: 0.000200] [Total loss: 0.000971]\n",
      "[Epoch 11800/20000] [MSE loss: 0.000005] [Phy loss: 0.000153] [Total loss: 0.000797]\n",
      "[Epoch 11900/20000] [MSE loss: 0.000008] [Phy loss: 0.000282] [Total loss: 0.001484]\n",
      "[Epoch 12000/20000] [MSE loss: 0.000005] [Phy loss: 0.000171] [Total loss: 0.000837]\n",
      "[Epoch 12100/20000] [MSE loss: 0.000005] [Phy loss: 0.000190] [Total loss: 0.000858]\n",
      "[Epoch 12200/20000] [MSE loss: 0.000004] [Phy loss: 0.000143] [Total loss: 0.000699]\n",
      "[Epoch 12300/20000] [MSE loss: 0.000011] [Phy loss: 0.000330] [Total loss: 0.001957]\n",
      "[Epoch 12400/20000] [MSE loss: 0.000004] [Phy loss: 0.000144] [Total loss: 0.000704]\n",
      "[Epoch 12500/20000] [MSE loss: 0.000004] [Phy loss: 0.000109] [Total loss: 0.000597]\n",
      "[Epoch 12600/20000] [MSE loss: 0.000003] [Phy loss: 0.000118] [Total loss: 0.000556]\n",
      "[Epoch 12700/20000] [MSE loss: 0.000005] [Phy loss: 0.000155] [Total loss: 0.000840]\n",
      "[Epoch 12800/20000] [MSE loss: 0.000004] [Phy loss: 0.000120] [Total loss: 0.000695]\n",
      "[Epoch 12900/20000] [MSE loss: 0.000005] [Phy loss: 0.000140] [Total loss: 0.000775]\n",
      "[Epoch 13000/20000] [MSE loss: 0.000005] [Phy loss: 0.000132] [Total loss: 0.000739]\n",
      "[Epoch 13100/20000] [MSE loss: 0.000006] [Phy loss: 0.000175] [Total loss: 0.001281]\n",
      "[Epoch 13200/20000] [MSE loss: 0.000006] [Phy loss: 0.000195] [Total loss: 0.001063]\n",
      "[Epoch 13600/20000] [MSE loss: 0.000003] [Phy loss: 0.000098] [Total loss: 0.000535]\n",
      "[Epoch 13700/20000] [MSE loss: 0.000005] [Phy loss: 0.000157] [Total loss: 0.001046]\n",
      "[Epoch 13800/20000] [MSE loss: 0.000011] [Phy loss: 0.000303] [Total loss: 0.001883]\n",
      "[Epoch 13900/20000] [MSE loss: 0.000004] [Phy loss: 0.000112] [Total loss: 0.000625]\n",
      "[Epoch 14000/20000] [MSE loss: 0.000005] [Phy loss: 0.000148] [Total loss: 0.000854]\n",
      "[Epoch 14100/20000] [MSE loss: 0.000003] [Phy loss: 0.000084] [Total loss: 0.000464]\n",
      "[Epoch 14200/20000] [MSE loss: 0.000005] [Phy loss: 0.000141] [Total loss: 0.000841]\n",
      "[Epoch 14300/20000] [MSE loss: 0.000004] [Phy loss: 0.000120] [Total loss: 0.000651]\n",
      "[Epoch 14400/20000] [MSE loss: 0.000005] [Phy loss: 0.000146] [Total loss: 0.000960]\n",
      "[Epoch 14500/20000] [MSE loss: 0.000004] [Phy loss: 0.000114] [Total loss: 0.000690]\n",
      "[Epoch 14600/20000] [MSE loss: 0.000007] [Phy loss: 0.000180] [Total loss: 0.001214]\n",
      "[Epoch 14700/20000] [MSE loss: 0.000005] [Phy loss: 0.000155] [Total loss: 0.000864]\n",
      "[Epoch 14800/20000] [MSE loss: 0.000005] [Phy loss: 0.000134] [Total loss: 0.000969]\n",
      "[Epoch 14900/20000] [MSE loss: 0.000006] [Phy loss: 0.000192] [Total loss: 0.001120]\n",
      "[Epoch 15000/20000] [MSE loss: 0.000008] [Phy loss: 0.000240] [Total loss: 0.001215]\n",
      "[Epoch 15100/20000] [MSE loss: 0.000003] [Phy loss: 0.000104] [Total loss: 0.000506]\n",
      "[Epoch 15200/20000] [MSE loss: 0.000008] [Phy loss: 0.000219] [Total loss: 0.001345]\n",
      "[Epoch 15300/20000] [MSE loss: 0.000003] [Phy loss: 0.000075] [Total loss: 0.000407]\n",
      "[Epoch 15400/20000] [MSE loss: 0.000003] [Phy loss: 0.000085] [Total loss: 0.000452]\n",
      "[Epoch 15500/20000] [MSE loss: 0.000008] [Phy loss: 0.000237] [Total loss: 0.001691]\n",
      "[Epoch 15600/20000] [MSE loss: 0.000005] [Phy loss: 0.000123] [Total loss: 0.000748]\n",
      "[Epoch 15700/20000] [MSE loss: 0.000005] [Phy loss: 0.000169] [Total loss: 0.000961]\n",
      "[Epoch 15800/20000] [MSE loss: 0.000006] [Phy loss: 0.000149] [Total loss: 0.001052]\n",
      "[Epoch 15900/20000] [MSE loss: 0.000006] [Phy loss: 0.000173] [Total loss: 0.001170]\n",
      "[Epoch 16000/20000] [MSE loss: 0.000007] [Phy loss: 0.000194] [Total loss: 0.001220]\n",
      "[Epoch 16100/20000] [MSE loss: 0.000005] [Phy loss: 0.000117] [Total loss: 0.000681]\n",
      "[Epoch 16200/20000] [MSE loss: 0.000004] [Phy loss: 0.000111] [Total loss: 0.000672]\n",
      "[Epoch 16300/20000] [MSE loss: 0.000003] [Phy loss: 0.000087] [Total loss: 0.000454]\n",
      "[Epoch 16400/20000] [MSE loss: 0.000003] [Phy loss: 0.000069] [Total loss: 0.000409]\n",
      "[Epoch 16500/20000] [MSE loss: 0.000003] [Phy loss: 0.000092] [Total loss: 0.000502]\n",
      "[Epoch 16600/20000] [MSE loss: 0.000004] [Phy loss: 0.000099] [Total loss: 0.000671]\n",
      "[Epoch 16700/20000] [MSE loss: 0.000003] [Phy loss: 0.000076] [Total loss: 0.000488]\n",
      "[Epoch 16800/20000] [MSE loss: 0.000008] [Phy loss: 0.000216] [Total loss: 0.001633]\n",
      "[Epoch 16900/20000] [MSE loss: 0.000005] [Phy loss: 0.000123] [Total loss: 0.000870]\n",
      "[Epoch 17000/20000] [MSE loss: 0.000003] [Phy loss: 0.000099] [Total loss: 0.000516]\n",
      "[Epoch 17100/20000] [MSE loss: 0.000004] [Phy loss: 0.000109] [Total loss: 0.000977]\n",
      "[Epoch 17200/20000] [MSE loss: 0.000003] [Phy loss: 0.000102] [Total loss: 0.000568]\n",
      "[Epoch 17300/20000] [MSE loss: 0.000006] [Phy loss: 0.000158] [Total loss: 0.001211]\n",
      "[Epoch 17400/20000] [MSE loss: 0.000006] [Phy loss: 0.000152] [Total loss: 0.001207]\n",
      "[Epoch 17500/20000] [MSE loss: 0.000006] [Phy loss: 0.000189] [Total loss: 0.001390]\n",
      "[Epoch 17600/20000] [MSE loss: 0.000004] [Phy loss: 0.000114] [Total loss: 0.000591]\n",
      "[Epoch 17700/20000] [MSE loss: 0.000004] [Phy loss: 0.000113] [Total loss: 0.000667]\n",
      "[Epoch 17800/20000] [MSE loss: 0.000011] [Phy loss: 0.000306] [Total loss: 0.002248]\n",
      "[Epoch 17900/20000] [MSE loss: 0.000003] [Phy loss: 0.000078] [Total loss: 0.000635]\n",
      "[Epoch 18000/20000] [MSE loss: 0.000005] [Phy loss: 0.000157] [Total loss: 0.000924]\n",
      "[Epoch 18100/20000] [MSE loss: 0.000004] [Phy loss: 0.000131] [Total loss: 0.000752]\n",
      "[Epoch 18200/20000] [MSE loss: 0.000003] [Phy loss: 0.000084] [Total loss: 0.000479]\n",
      "[Epoch 18300/20000] [MSE loss: 0.000003] [Phy loss: 0.000086] [Total loss: 0.000442]\n",
      "[Epoch 18400/20000] [MSE loss: 0.000008] [Phy loss: 0.000198] [Total loss: 0.001216]\n",
      "[Epoch 18500/20000] [MSE loss: 0.000004] [Phy loss: 0.000104] [Total loss: 0.000563]\n",
      "[Epoch 18600/20000] [MSE loss: 0.000004] [Phy loss: 0.000106] [Total loss: 0.000645]\n",
      "[Epoch 18700/20000] [MSE loss: 0.000004] [Phy loss: 0.000115] [Total loss: 0.000759]\n",
      "[Epoch 18800/20000] [MSE loss: 0.000004] [Phy loss: 0.000098] [Total loss: 0.000605]\n",
      "[Epoch 18900/20000] [MSE loss: 0.000003] [Phy loss: 0.000062] [Total loss: 0.000546]\n",
      "[Epoch 19000/20000] [MSE loss: 0.000004] [Phy loss: 0.000092] [Total loss: 0.000636]\n",
      "[Epoch 19100/20000] [MSE loss: 0.000005] [Phy loss: 0.000142] [Total loss: 0.000833]\n",
      "[Epoch 19200/20000] [MSE loss: 0.000004] [Phy loss: 0.000096] [Total loss: 0.000772]\n"
     ]
    }
   ],
   "source": [
    "net = Net(in_dim = 2, out_dim = 1, hid_dim = hid_dim, num_layers = num_layer).to(device)\n",
    "\n",
    "ACs = AC_PINN(X0_1, Y0_1, X_f_1, X_lb_1, X_ub_1, net, device, num_epochs_1, 1, noise)\n",
    " \n",
    "ACs.train(True,trunk1_X,trunk1_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 1\n",
    "u_pred_list = []\n",
    "f_u_pred_list = []\n",
    "\n",
    "for run in range(nsamples):\n",
    "    y_pred, f_u_pred = ACs.get_residual(trunk1_X)\n",
    "    u_pred = y_pred[:,0:1].detach().cpu().numpy()\n",
    "    u_pred_list.append(u_pred)\n",
    "    f_u_pred_list.append(f_u_pred.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "u_pred_arr = np.array(u_pred_list)\n",
    "f_u_pred_arr = np.array(f_u_pred_list)\n",
    "\n",
    "u_pred = u_pred_arr.mean(axis=0)\n",
    "f_u_pred = f_u_pred_arr.mean(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "residual = (f_u_pred**2).mean()\n",
    "\n",
    "#     u_dev = u_pred_arr.var(axis=0)\n",
    "#     f_dev = f_pred_arr.var(axis=0)\n",
    "\n",
    "error_u = np.linalg.norm(trunk1_u-u_pred,2)/np.linalg.norm(trunk1_u,2)\n",
    "\n",
    "print(\"Error u:\", error_u)                   \n",
    "print('Residual: %e' % (residual))\n",
    "\n",
    "# --------------------- Second half ---------------------\n",
    "\n",
    "tmp_pred = u_pred[-512:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred = u_pred[-512:]\n",
    "\n",
    "# initial points\n",
    "\n",
    "idx_x = np.random.choice(x.shape[0], 512, replace=False)\n",
    "x0_2 = x[idx_x,:]\n",
    "u0_2 = u_pred[-512:][idx_x,0:1]\n",
    "\n",
    "\n",
    "# x0_2 = x\n",
    "# u0_2 = u_pred[-512:]\n",
    "\n",
    "# boundary points\n",
    "idx_t = np.random.choice(range(tt, 201), N_b, replace=False)\n",
    "tb_2 = t[idx_t,:]\n",
    "\n",
    "# collocation points\n",
    "X_f_2 = second_lb + (second_ub-second_lb)*lhs(2, N_f)\n",
    "\n",
    "X0_2 = np.concatenate((x[idx_x,:], \n",
    "                       np.full(x[idx_x,:].shape, first_ub[1])), 1) # (x0, 0)\n",
    "\n",
    "\n",
    "\n",
    "Y0_2 = u0_2\n",
    "X_lb_2 = np.concatenate((0*tb_2 + second_lb[0], tb_2), 1) # (lb[0], tb)\n",
    "X_ub_2 = np.concatenate((0*tb_2 + second_ub[0], tb_2), 1) # (ub[0], tb)\n",
    "\n",
    "\n",
    "num_epochs = 20000\n",
    "\n",
    "PINN = AC_PINN(np.vstack([X0_1,X0_2]),\n",
    "                        np.vstack([Y0_1,Y0_2]),\n",
    "                        np.vstack([X_f_1,X_f_2]), \n",
    "                        np.vstack([X_lb_1,X_lb_2]), \n",
    "                        np.vstack([X_ub_1,X_ub_2]), \n",
    "                        net, \n",
    "                        device, \n",
    "                        num_epochs_2, \n",
    "                        1.0, \n",
    "                        noise)\n",
    "PINN.train(False,X_star,u_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 1\n",
    "u_pred_list = []\n",
    "f_u_pred_list = []\n",
    "\n",
    "for run in range(1):\n",
    "    y_pred, f_u_pred = PINN.get_residual(X_star)\n",
    "    u_pred = y_pred[:,0:1].detach().cpu().numpy()\n",
    "    u_pred_list.append(u_pred)\n",
    "    f_u_pred_list.append(f_u_pred.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "u_pred_arr = np.array(u_pred_list)\n",
    "f_u_pred_arr = np.array(f_u_pred_list)\n",
    "\n",
    "\n",
    "u_pred = u_pred_arr.mean(axis=0)\n",
    "f_u_pred = f_u_pred_arr.mean(axis=0)\n",
    "residual = (f_u_pred**2).mean()\n",
    "\n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "\n",
    "\n",
    "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
    "FU_pred = griddata(X_star, f_u_pred.flatten(), (X, T), method='cubic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error u:\", error_u)                  \n",
    "print('Residual: %e' % (residual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "############################# Plotting ###############################\n",
    "######################################################################    \n",
    "# t = data['tt'].flatten()[:,None]\n",
    "# x = data['x'].flatten()[:,None]\n",
    "\n",
    "# X0 = np.concatenate((x0, 0*x0), 1) # (x0, 0)\n",
    "# X_lb = np.concatenate((0*tb + lb[0], tb), 1) # (lb[0], tb)\n",
    "# X_ub = np.concatenate((0*tb + ub[0], tb), 1) # (ub[0], tb)\n",
    "# X_u_train = np.vstack([X0, X_lb, X_ub])\n",
    "\n",
    "# fig, ax = newfig(1.0, 0.9)\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axis('off')\n",
    "\n",
    "####### Row 0: h(t,x) ##################    \n",
    "gs0 = gridspec.GridSpec(1, 2)\n",
    "gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
    "ax = plt.subplot(gs0[:, :])\n",
    "\n",
    "h = ax.imshow(Exact, interpolation='nearest', cmap='YlGnBu', \n",
    "              extent=[lb[1], ub[1], lb[0], ub[0]], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(h, cax=cax)\n",
    "\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$x$')\n",
    "leg = ax.legend(frameon=False, loc = 'best')\n",
    "#    plt.setp(leg.get_texts(), color='w')\n",
    "ax.set_title('Prediction $|h(t,x)|$', fontsize = 10)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axis('off')\n",
    "\n",
    "####### Row 0: h(t,x) ##################    \n",
    "gs0 = gridspec.GridSpec(1, 2)\n",
    "gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
    "ax = plt.subplot(gs0[:, :])\n",
    "\n",
    "# error  = griddata(X_star, np.abs(u_star-U_pred).flatten(), (X, T), method='cubic')\n",
    "\n",
    "\n",
    "h = ax.imshow(U_pred.T, interpolation='nearest', cmap='YlGnBu', \n",
    "              extent=[lb[1], ub[1], lb[0], ub[0]], \n",
    "              origin='lower', aspect='auto')\n",
    "\n",
    "\n",
    "# h = ax.imshow(np.abs(Exact - U_pred.T), interpolation='nearest', cmap='YlGnBu', \n",
    "#               extent=[lb[1], ub[1], lb[0], ub[0]], \n",
    "#               origin='lower', aspect='auto')\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(h, cax=cax)\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$x$')\n",
    "leg = ax.legend(frameon=False, loc = 'best')\n",
    "#    plt.setp(leg.get_texts(), color='w')\n",
    "ax.set_title('Error $u(x,t)$', fontsize = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Row 1: h(t,x) slices ##################    \n",
    "fig = plt.figure(figsize=(40, 20))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# b = np.loadtxt('PINN_result.txt',dtype=float)\n",
    "\n",
    "gs1 = gridspec.GridSpec(1, 4)\n",
    "gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5)\n",
    "\n",
    "ax = plt.subplot(gs1[0, 0])\n",
    "ax.plot(x,Exact[:,tt], 'b-', linewidth = 2, label = 'Exact')       \n",
    "ax.plot(x,tmp_pred, 'r--', linewidth = 2, label = 'Prediction')\n",
    "ax.plot(x,U_pred.T[:,tt], 'g--', linewidth = 2, label = 'Prediction')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$|h(t,x)|$')    \n",
    "ax.set_title('Standard PINN', fontsize = 10)\n",
    "ax.axis('square')\n",
    "ax.set_xlim([-1.1,1.1])\n",
    "ax.set_ylim([-0.1,1.1])\n",
    "\n",
    "# ax = plt.subplot(gs1[0, 1])\n",
    "# ax.plot(x,Exact[:,tt], 'b-', linewidth = 2, label = 'Exact')       \n",
    "# ax.plot(x,tmp_pred, 'r--', linewidth = 2, label = 'Prediction')\n",
    "\n",
    "# ax.set_xlabel('$x$')\n",
    "# ax.set_ylabel('$|h(t,x)|$')\n",
    "# ax.axis('square')\n",
    "# ax.set_xlim([-5.1,5.1])\n",
    "# ax.set_ylim([-0.1,5.1])\n",
    "# ax.set_title('PL-PINN (phase 1)', fontsize = 10)\n",
    "# ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.8), ncol=5, frameon=False)\n",
    "\n",
    "# ax = plt.subplot(gs1[0, 2])\n",
    "# ax.plot(x,Exact[:,tt], 'b-', linewidth = 2, label = 'Exact')       \n",
    "# ax.plot(x,H_pred[tt,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "\n",
    "# ax.set_xlabel('$x$')\n",
    "# ax.set_ylabel('$|h(t,x)|$')\n",
    "# ax.axis('square')\n",
    "# ax.set_xlim([-5.1,5.1])\n",
    "# ax.set_ylim([-0.1,5.1])    \n",
    "# ax.set_title('PL-PINN (phase 2)', fontsize = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
